Role: Data Engineer | Duration: May 2025 | [GitHub Link] 
Tech: Apache Airflow, PySpark, Power BI, DockerS 
•           Developed a modular ETL system in Airflow + PySpark to process 1.2M+ multi-year traffic 
records across 35+ regions and 5+ vehicle types — achieving daily refreshes with 99.9% uptime. 
•         Built robust cleansing and transformation layers to resolve nulls, handle outliers, and flatten 
nested schemas — improving downstream analytics performance by 35%. 
•      Computed region-level congestion scores, peak hour densities, and vehicle-type trends — 
enabling government analysts to identify 15+ critical traffic bottlenecks. 
•         Stored optimized data as partitioned Parquet files, reducing query latency by 40% and 
supporting fast integration with BI tools. 
•        Designed an interactive Power BI dashboard with real-time filters (year, region, road type), 
surfacing insights such as: 
o Top 10 most congested roads 
o Vehicle-type trends by geography 
o Peak-hour traffic patterns 
•     Implemented Airflow DAGs with retries, alerts, and dependency handling — eliminating 
manual interventions and reducing error recovery time by 80%. 
•      Added real-time schema validation and logging at each ETL stage, decreasing data corruption 
incidents by 90% and improving error traceability by 60%. 
       Real-World Impact: 
• Urban Planning: Helps policymakers allocate budgets based on traffic density hotspots. 
• Insurance Analytics: Enables insurers to evaluate accident-prone zones using historical congestion 
data. 
